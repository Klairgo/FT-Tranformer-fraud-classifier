{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62nwlas_3O1",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# PyTorch TabNet Fraud Classification\n",
        "\n",
        "This notebook implements a fraud detection classifier using FT-Transformer on balanced training data.\n",
        "\n",
        "## Objectives:\n",
        "1. Load and prepare balanced fraud detection datasets\n",
        "2. Build and train a FT-Transformer classifier\n",
        "3. Evaluate model performance on the original imbalanced test set\n",
        "4. Analyze feature importance and model interpretability"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6YBJekezQrq",
        "outputId": "04e77ff5-8194-488f-940a-dab70bf168b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i0-kYaVz_3O4"
      },
      "outputs": [],
      "source": [
        "# Variables\n",
        "train_dataset_path = '../data/train.csv'\n",
        "test_dataset_path = '../data/test.csv'\n",
        "metadata_path = '../data/preprocessing_metadata.json'\n",
        "class_label = 'Class'\n",
        "random_seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLR5lOXZ_3O5"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import json\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import platform\n",
        "import sys\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from rtdl_revisiting_models import FTTransformer\n",
        "from typing import Dict, Any, Optional, Tuple, Union\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    precision_recall_curve, roc_curve, average_precision_score,\n",
        "    balanced_accuracy_score, matthews_corrcoef\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set multiprocessing start method for Jupyter compatibility\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "    print(\"Multiprocessing start method set to 'spawn' for Jupyter compatibility\")\n",
        "except RuntimeError:\n",
        "    print(\"Multiprocessing start method already set\")\n",
        "\n",
        "# Disable multiprocessing in DataLoaders for Jupyter safety\n",
        "os.environ['PYTORCH_DATALOADER_NUM_WORKERS'] = '0'\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "    # Ensure deterministic behavior on CUDA\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "def log_environment_info():\n",
        "    \"\"\"\n",
        "    Log comprehensive environment information for reproducibility debugging\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ENVIRONMENT INFORMATION (FOR REPRODUCIBILITY)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(f\"Platform: {platform.platform()}\")\n",
        "    print(f\"Python version: {sys.version}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"NumPy version: {np.__version__}\")\n",
        "    print(f\"Pandas version: {pd.__version__}\")\n",
        "\n",
        "    # Import and check other key packages\n",
        "    try:\n",
        "        import sklearn\n",
        "        print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"scikit-learn: Not available\")\n",
        "\n",
        "    try:\n",
        "        import rtdl_revisiting_models\n",
        "        print(f\"rtdl-revisiting-models version: {rtdl_revisiting_models.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"rtdl-revisiting-models: Not available\")\n",
        "\n",
        "    # CUDA information\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"CUDNN version: {torch.backends.cudnn.version()}\")\n",
        "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            props = torch.cuda.get_device_properties(i)\n",
        "            print(f\"CUDA device {i}: {props.name}\")\n",
        "            print(f\"  Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
        "            print(f\"  Compute capability: {props.major}.{props.minor}\")\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Environment variables\n",
        "    print(f\"CUBLAS_WORKSPACE_CONFIG: {os.environ.get('CUBLAS_WORKSPACE_CONFIG', 'Not set')}\")\n",
        "    print(f\"PYTORCH_DATALOADER_NUM_WORKERS: {os.environ.get('PYTORCH_DATALOADER_NUM_WORKERS', 'Not set')}\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    return device\n",
        "\n",
        "device = log_environment_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhaHMKsk_3O7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Data Loading and Exploration\n",
        "\n",
        "Loading the balanced training data and original test data for fraud detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qlT-yLt_3O7",
        "outputId": "6d21b3ed-39d5-4a12-e293-ab906f425d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Balanced training data shape: (409412, 31)\n",
            "Test data shape: (28481, 31)\n",
            "\n",
            "=== Training Data Info ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 100 entries, 247844 to 324494\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Time    100 non-null    float64\n",
            " 1   V1      100 non-null    float64\n",
            " 2   V2      100 non-null    float64\n",
            " 3   V3      100 non-null    float64\n",
            " 4   V4      100 non-null    float64\n",
            " 5   V5      100 non-null    float64\n",
            " 6   V6      100 non-null    float64\n",
            " 7   V7      100 non-null    float64\n",
            " 8   V8      100 non-null    float64\n",
            " 9   V9      100 non-null    float64\n",
            " 10  V10     100 non-null    float64\n",
            " 11  V11     100 non-null    float64\n",
            " 12  V12     100 non-null    float64\n",
            " 13  V13     100 non-null    float64\n",
            " 14  V14     100 non-null    float64\n",
            " 15  V15     100 non-null    float64\n",
            " 16  V16     100 non-null    float64\n",
            " 17  V17     100 non-null    float64\n",
            " 18  V18     100 non-null    float64\n",
            " 19  V19     100 non-null    float64\n",
            " 20  V20     100 non-null    float64\n",
            " 21  V21     100 non-null    float64\n",
            " 22  V22     100 non-null    float64\n",
            " 23  V23     100 non-null    float64\n",
            " 24  V24     100 non-null    float64\n",
            " 25  V25     100 non-null    float64\n",
            " 26  V26     100 non-null    float64\n",
            " 27  V27     100 non-null    float64\n",
            " 28  V28     100 non-null    float64\n",
            " 29  Amount  100 non-null    float64\n",
            " 30  Class   100 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 25.0 KB\n",
            "None\n",
            "\n",
            "Class distribution in training data:\n",
            "Class\n",
            "0    64\n",
            "1    36\n",
            "Name: count, dtype: int64\n",
            "Training fraud percentage: 36.00%\n",
            "\n",
            "=== Test Data Info ===\n",
            "\n",
            "Class distribution in test data:\n",
            "Class\n",
            "0    28432\n",
            "1       49\n",
            "Name: count, dtype: int64\n",
            "Test fraud percentage: 0.17%\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Load balanced training data (SMOTE applied)\n",
        "train_df = pd.read_csv(train_dataset_path)\n",
        "print(f\"Balanced training data shape: {train_df.shape}\")\n",
        "\n",
        "# train_df = train_df.sample(n=100, random_state=random_seed)\n",
        "\n",
        "# Load original test data (imbalanced)\n",
        "test_df = pd.read_csv(test_dataset_path)\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\n=== Training Data Info ===\")\n",
        "print(train_df.info())\n",
        "print(f\"\\nClass distribution in training data:\")\n",
        "print(train_df[class_label].value_counts())\n",
        "print(f\"Training fraud percentage: {train_df[class_label].mean()*100:.2f}%\")\n",
        "\n",
        "print(\"\\n=== Test Data Info ===\")\n",
        "print(f\"\\nClass distribution in test data:\")\n",
        "print(test_df[class_label].value_counts())\n",
        "print(f\"Test fraud percentage: {test_df[class_label].mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "EQpPx7J2_3O8",
        "outputId": "d285289f-2720-46fa-e410-baf6305de85d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of training data:\n",
            "            Time        V1        V2        V3        V4        V5        V6  \\\n",
            "247844 -0.764821 -0.386307 -0.020626  1.501715  1.217956 -0.346173  0.779219   \n",
            "330420 -0.200658 -3.576095  2.096939 -6.293900  3.715671 -2.982455 -2.104080   \n",
            "190966 -1.616972  0.153836 -1.209573 -0.040527 -1.062486 -1.149413 -0.804646   \n",
            "34141  -1.516715 -0.222012  1.228439 -1.877754  1.360613  0.439889 -1.213748   \n",
            "327039 -0.017142 -6.232028  4.605833 -9.599403  5.600989 -7.672190 -2.000607   \n",
            "\n",
            "               V7        V8        V9  ...       V21       V22       V23  \\\n",
            "247844   0.028280  0.430033  0.317677  ... -0.218506 -0.375892  0.476583   \n",
            "330420  -5.580400  3.160045 -4.212340  ...  1.485643 -0.736466  0.070947   \n",
            "190966   0.128853 -0.248942  2.758896  ...  0.558902  0.607743 -0.957192   \n",
            "34141    0.303722  0.343796  0.604125  ... -0.375105 -0.596339  0.097165   \n",
            "327039 -12.595384  2.234421 -5.452788  ...  0.377970  0.555720  0.368942   \n",
            "\n",
            "             V24       V25       V26       V27       V28    Amount  Class  \n",
            "247844  0.326205 -0.893376 -0.990106  0.482435  0.494881  0.069128      0  \n",
            "330420 -0.584845  0.684729  2.167314  3.426869 -0.854919 -0.270780      1  \n",
            "190966  0.904104  0.919004 -1.545298 -0.126121  0.293262  1.666124      0  \n",
            "34141  -0.788875 -0.576735 -0.837001  0.504931 -0.583283  0.006558      0  \n",
            "327039  1.177097 -0.477444 -0.724415 -3.341144 -0.965799 -0.189378      1  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# Visualize class distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Training data distribution\n",
        "train_counts = train_df[class_label].value_counts()\n",
        "axes[0].pie(train_counts.values, labels=['Non-Fraud', 'Fraud'], autopct='%1.1f%%', startangle=90)\n",
        "axes[0].set_title('Training Data Class Distribution\\n(SMOTE Balanced)')\n",
        "\n",
        "# Test data distribution\n",
        "test_counts = test_df[class_label].value_counts()\n",
        "axes[1].pie(test_counts.values, labels=['Non-Fraud', 'Fraud'], autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Test Data Class Distribution\\n(Original Imbalanced)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display first few rows\n",
        "print(\"Sample of training data:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8EbMEzC_3O9",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Data Preprocessing for FT-Transformer\n",
        "\n",
        "Preparing the data for TabNet training including feature separation and encoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2Vbut1C_3O9",
        "outputId": "44511f81-4259-47c4-bf09-19e1215f7115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded metadata: {'original_dataset_shape': [284807, 31], 'feature_columns': ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'], 'target_column': 'Class', 'scaling_method': 'StandardScaler', 'balancing_method': 'smote', 'train_test_split_ratio': '80:20', 'random_seed': 42, 'class_distribution_original': {'non_fraud': 284315, 'fraud': 492, 'imbalance_ratio': 577.8760162601626}, 'class_distribution_train_final': {'non_fraud': 255883, 'fraud': 153529, 'imbalance_ratio': 1.6666753512365742, 'sampling_technique': 'smote'}, 'class_distribution_test_final': {'non_fraud': 28432, 'fraud': 49, 'imbalance_ratio': 580.2448979591836, 'note': 'Original imbalanced distribution for realistic evaluation'}}\n",
            "Feature columns: 30\n",
            "Training samples: 100\n",
            "Test samples: 28481\n",
            "Metadata feature order: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
            "Current feature order: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
            "\n",
            "Converted to numpy arrays for TabNet compatibility\n",
            "X_train type: <class 'numpy.ndarray'>, shape: (100, 30)\n",
            "X_test type: <class 'numpy.ndarray'>, shape: (28481, 30)\n",
            "\n",
            "Final shapes:\n",
            "X_train: (100, 30)\n",
            "y_train: (100,)\n",
            "X_test: (28481, 30)\n",
            "y_test: (28481,)\n",
            "Class distribution in y_train: [64 36]\n",
            "Class distribution in y_test: [28432    49]\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing for TabNet\n",
        "def preprocess_data(train_df, test_df):\n",
        "    \"\"\"\n",
        "    Preprocess data for TabNet training\n",
        "\n",
        "    Returns:\n",
        "        X_train, y_train, X_test, y_test, cat_idxs, cat_dims\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    with open(metadata_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "    print(f\"Loaded metadata: {metadata}\")\n",
        "\n",
        "    # Separate features and target\n",
        "    feature_cols = [col for col in train_df.columns if col != class_label]\n",
        "\n",
        "    X_train = train_df[feature_cols].copy()\n",
        "    y_train = train_df[class_label].values.astype(int)\n",
        "\n",
        "    X_test = test_df[feature_cols].copy()\n",
        "    y_test = test_df[class_label].values.astype(int)\n",
        "\n",
        "    print(f\"Feature columns: {len(feature_cols)}\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "    categorical_cols = []\n",
        "    numerical_cols = [col for col in feature_cols if col not in categorical_cols]\n",
        "\n",
        "\n",
        "    # Get categorical info from metadata but verify against current feature order\n",
        "    metadata_features = metadata.get('feature_columns', [])\n",
        "\n",
        "    print(f\"Metadata feature order: {metadata_features}\")\n",
        "    print(f\"Current feature order: {feature_cols}\")\n",
        "\n",
        "    # Convert DataFrames to numpy arrays for TabNet (required)\n",
        "    X_train = X_train.values.astype(np.float32)\n",
        "    X_test = X_test.values.astype(np.float32)\n",
        "\n",
        "    print(f\"\\nConverted to numpy arrays for TabNet compatibility\")\n",
        "    print(f\"X_train type: {type(X_train)}, shape: {X_train.shape}\")\n",
        "    print(f\"X_test type: {type(X_test)}, shape: {X_test.shape}\")\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, feature_cols, numerical_cols\n",
        "\n",
        "# Preprocess the data\n",
        "X_train, y_train, X_test, y_test, feature_names, numerical_cols = preprocess_data(train_df, test_df)\n",
        "\n",
        "print(f\"\\nFinal shapes:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "print(f\"Class distribution in y_train: {np.bincount(y_train)}\")\n",
        "print(f\"Class distribution in y_test: {np.bincount(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa6uIaSw_3O-",
        "outputId": "7da858a5-4a76-4f0f-9b61-6a7f35559db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training split: (90, 30)\n",
            "Validation split: (10, 30)\n"
          ]
        }
      ],
      "source": [
        "# Create validation split from training data\n",
        "X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
        "y_train_df = pd.DataFrame(y_train, columns=[class_label])\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train_df, y_train_df,\n",
        "    test_size=0.1,\n",
        "    random_state=random_seed,\n",
        "    stratify=y_train_df\n",
        ")\n",
        "\n",
        "print(f\"Training split: {X_train_split.shape}\")\n",
        "print(f\"Validation split: {X_val.shape}\")\n",
        "\n",
        "#Final data processing:\n",
        "X_train_num = X_train_split[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "y_train = y_train_split.reset_index(drop=True).to_numpy()\n",
        "\n",
        "X_val_num = X_val[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "y_val_val = y_val.reset_index(drop=True).to_numpy()\n",
        "\n",
        "categorical_cols = []\n",
        "cat_dims = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veIgrYd7_3PA",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. FT-Transformer Model Definition and Training\n",
        "\n",
        "Building and training the TabNet classifier with optimized hyperparameters for fraud detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GWWThBHF_3PE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Comprehensive Model Evaluation for Fraud Detection\n",
        "\"\"\"\n",
        "def comprehensive_model_test(\n",
        "    model,\n",
        "    X_test: Union[np.ndarray, pd.DataFrame],\n",
        "    y_test: Union[np.ndarray, pd.Series],\n",
        "    model_name: str = \"Model\",\n",
        "    feature_names: Optional[list] = None,\n",
        "    class_names: Optional[list] = None,\n",
        "    threshold: float = 0.5,\n",
        "    save_results: bool = True,\n",
        "    results_dir: str = \"../results/\",\n",
        "    plot_results: bool = True,\n",
        "    detailed_report: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Comprehensive testing function for fraud detection models.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Starting comprehensive evaluation for {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Set default class names\n",
        "    if class_names is None:\n",
        "        class_names = ['Non-Fraud', 'Fraud']\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'test_set_size': len(y_test),\n",
        "        'evaluation_timestamp': datetime.now().isoformat(),\n",
        "        'threshold': threshold\n",
        "    }\n",
        "\n",
        "    # 1. Make predictions\n",
        "    print(\"Making predictions...\")\n",
        "    try:\n",
        "        # Get probability predictions\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_pred_proba = model.predict_proba(X_test)\n",
        "            if y_pred_proba.shape[1] == 2:\n",
        "                y_pred_proba_fraud = y_pred_proba[:, 1]  # Probability of fraud\n",
        "            else:\n",
        "                y_pred_proba_fraud = y_pred_proba.flatten()\n",
        "        else:\n",
        "            raise AttributeError(\"Model must have predict_proba method\")\n",
        "\n",
        "        # Get binary predictions\n",
        "        if hasattr(model, 'predict'):\n",
        "            y_pred = model.predict(X_test)\n",
        "        else:\n",
        "            y_pred = (y_pred_proba_fraud >= threshold).astype(int)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error making predictions: {e}\")\n",
        "        return {'error': str(e)}\n",
        "\n",
        "    # 2. Calculate basic metrics\n",
        "    print(\"Calculating performance metrics...\")\n",
        "\n",
        "    # Basic classification metrics\n",
        "    basic_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'f1_score': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'matthews_corrcoef': matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # ROC and PR metrics\n",
        "    try:\n",
        "        basic_metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba_fraud)\n",
        "        basic_metrics['pr_auc'] = average_precision_score(y_test, y_pred_proba_fraud)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not calculate AUC metrics: {e}\")\n",
        "        basic_metrics['roc_auc'] = None\n",
        "        basic_metrics['pr_auc'] = None\n",
        "\n",
        "    results['basic_metrics'] = basic_metrics\n",
        "\n",
        "    # 3. Confusion Matrix Analysis\n",
        "    print(\"Analyzing confusion matrix...\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Calculate confusion matrix components\n",
        "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
        "\n",
        "    confusion_analysis = {\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'true_negatives': int(tn),\n",
        "        'false_positives': int(fp),\n",
        "        'false_negatives': int(fn),\n",
        "        'true_positives': int(tp),\n",
        "        'total_fraud_detected': int(tp),\n",
        "        'total_fraud_missed': int(fn),\n",
        "        'false_alarm_rate': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        'true_negative_rate': tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    }\n",
        "\n",
        "    results['confusion_analysis'] = confusion_analysis\n",
        "\n",
        "    # 4. Class Distribution Analysis\n",
        "    print(\"Analyzing class distributions...\")\n",
        "\n",
        "    class_distribution = {\n",
        "        'test_set': {\n",
        "            'non_fraud': int((y_test == 0).sum()),\n",
        "            'fraud': int((y_test == 1).sum()),\n",
        "            'fraud_percentage': float((y_test == 1).mean() * 100)\n",
        "        },\n",
        "        'predictions': {\n",
        "            'predicted_non_fraud': int((y_pred == 0).sum()),\n",
        "            'predicted_fraud': int((y_pred == 1).sum()),\n",
        "            'predicted_fraud_percentage': float((y_pred == 1).mean() * 100)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    results['class_distribution'] = class_distribution\n",
        "\n",
        "    # 5. Fraud Detection Specific Metrics\n",
        "    print(\"Calculating fraud-specific metrics...\")\n",
        "\n",
        "    fraud_metrics = {\n",
        "        'fraud_detection_rate': tp / (tp + fn) if (tp + fn) > 0 else 0,  # Same as recall\n",
        "        'fraud_precision': tp / (tp + fp) if (tp + fp) > 0 else 0,       # Same as precision\n",
        "        'false_positive_rate': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,           # True negative rate\n",
        "        'negative_predictive_value': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
        "        'fraud_cases_total': int((y_test == 1).sum()),\n",
        "        'fraud_cases_detected': int(tp),\n",
        "        'fraud_cases_missed': int(fn)\n",
        "    }\n",
        "\n",
        "    results['fraud_metrics'] = fraud_metrics\n",
        "\n",
        "    # 5.5. Classification Report\n",
        "    print(\"Generating classification report...\")\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(\n",
        "        y_test, y_pred,\n",
        "        target_names=class_names,\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    # Store classification report\n",
        "    results['classification_report'] = class_report\n",
        "\n",
        "    # Print formatted classification report\n",
        "    print(\"\\nCLASSIFICATION REPORT\")\n",
        "    print(\"-\" * 50)\n",
        "    class_report_str = classification_report(\n",
        "        y_test, y_pred,\n",
        "        target_names=class_names,\n",
        "        zero_division=0,\n",
        "        digits=4\n",
        "    )\n",
        "    print(class_report_str)\n",
        "\n",
        "    # 6. Threshold Analysis\n",
        "    if detailed_report:\n",
        "        print(\"Performing threshold analysis...\")\n",
        "        threshold_analysis = analyze_thresholds(y_test, y_pred_proba_fraud)\n",
        "        results['threshold_analysis'] = threshold_analysis\n",
        "\n",
        "    # 7. Probability Distribution Analysis\n",
        "    print(\"Analyzing prediction probabilities...\")\n",
        "    prob_analysis = analyze_probability_distributions(y_test, y_pred_proba_fraud)\n",
        "    results['probability_analysis'] = prob_analysis\n",
        "\n",
        "\n",
        "    # 9. Feature importance (if available)\n",
        "    if hasattr(model, 'feature_importances_') and feature_names is not None:\n",
        "        print(\"Extracting feature importance...\")\n",
        "        feature_importance = extract_feature_importance(model, feature_names)\n",
        "        results['feature_importance'] = feature_importance\n",
        "\n",
        "    # 10. Generate summary report\n",
        "    summary = generate_summary_report(results)\n",
        "    results['summary_report'] = summary\n",
        "\n",
        "    # 11. Print summary\n",
        "    if(detailed_report):\n",
        "      print_evaluation_summary(results)\n",
        "\n",
        "    # 12. Generate visualizations\n",
        "    if plot_results:\n",
        "        print(\"Generating visualizations...\")\n",
        "        plots = generate_evaluation_plots(\n",
        "            y_test, y_pred, y_pred_proba_fraud,\n",
        "            model_name, class_names, save_results, results_dir\n",
        "        )\n",
        "        results['plots_generated'] = plots\n",
        "\n",
        "    # # 11. Save results\n",
        "    # if save_results:\n",
        "    #     print(\"Saving results...\")\n",
        "    #     save_evaluation_results(results, results_dir, model_name)\n",
        "\n",
        "\n",
        "    print(f\"\\n Evaluation completed for {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_thresholds(y_true: np.ndarray, y_pred_proba: np.ndarray,\n",
        "                      n_thresholds: int = 100) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyze performance across different classification thresholds.\n",
        "    \"\"\"\n",
        "\n",
        "    thresholds = np.linspace(0, 1, n_thresholds)\n",
        "    threshold_metrics = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_thresh = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        if len(np.unique(y_pred_thresh)) > 1:  # Avoid issues with all same predictions\n",
        "            precision = precision_score(y_true, y_pred_thresh, zero_division=0)\n",
        "            recall = recall_score(y_true, y_pred_thresh, zero_division=0)\n",
        "            f1 = f1_score(y_true, y_pred_thresh, zero_division=0)\n",
        "        else:\n",
        "            precision = recall = f1 = 0\n",
        "\n",
        "        threshold_metrics.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1\n",
        "        })\n",
        "\n",
        "    # Find optimal threshold based on F1 score\n",
        "    best_f1_idx = np.argmax([m['f1_score'] for m in threshold_metrics])\n",
        "    optimal_threshold = threshold_metrics[best_f1_idx]\n",
        "\n",
        "    return {\n",
        "        'threshold_metrics': threshold_metrics,\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'optimal_threshold_value': optimal_threshold['threshold']\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_probability_distributions(y_true: np.ndarray, y_pred_proba: np.ndarray) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyze the distribution of predicted probabilities for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    fraud_probs = y_pred_proba[y_true == 1]\n",
        "    non_fraud_probs = y_pred_proba[y_true == 0]\n",
        "\n",
        "    analysis = {\n",
        "        'fraud_probability_stats': {\n",
        "            'mean': float(np.mean(fraud_probs)) if len(fraud_probs) > 0 else 0,\n",
        "            'median': float(np.median(fraud_probs)) if len(fraud_probs) > 0 else 0,\n",
        "            'std': float(np.std(fraud_probs)) if len(fraud_probs) > 0 else 0,\n",
        "            'min': float(np.min(fraud_probs)) if len(fraud_probs) > 0 else 0,\n",
        "            'max': float(np.max(fraud_probs)) if len(fraud_probs) > 0 else 0\n",
        "        },\n",
        "        'non_fraud_probability_stats': {\n",
        "            'mean': float(np.mean(non_fraud_probs)) if len(non_fraud_probs) > 0 else 0,\n",
        "            'median': float(np.median(non_fraud_probs)) if len(non_fraud_probs) > 0 else 0,\n",
        "            'std': float(np.std(non_fraud_probs)) if len(non_fraud_probs) > 0 else 0,\n",
        "            'min': float(np.min(non_fraud_probs)) if len(non_fraud_probs) > 0 else 0,\n",
        "            'max': float(np.max(non_fraud_probs)) if len(non_fraud_probs) > 0 else 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Calculate probability separation\n",
        "    if len(fraud_probs) > 0 and len(non_fraud_probs) > 0:\n",
        "        separation_score = np.mean(fraud_probs) - np.mean(non_fraud_probs)\n",
        "        analysis['probability_separation_score'] = float(separation_score)\n",
        "    else:\n",
        "        analysis['probability_separation_score'] = 0.0\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def generate_evaluation_plots(y_true: np.ndarray, y_pred: np.ndarray, y_pred_proba: np.ndarray,\n",
        "                            model_name: str, class_names: list, save_plots: bool = True,\n",
        "                            save_dir: str = \"../results/\") -> list:\n",
        "    \"\"\"\n",
        "    Generate comprehensive evaluation plots.\n",
        "    \"\"\"\n",
        "\n",
        "    plots_generated = []\n",
        "\n",
        "    # Set up the plotting style\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    # 1. Confusion Matrix Heatmap\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "    ax.set_title(f'{model_name} - Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{save_dir}{model_name}_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
        "        plots_generated.append(f\"{model_name}_confusion_matrix.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # 2. ROC Curve and PR Curve\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # ROC Curve\n",
        "    try:\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "        axes[0].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "        axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "        axes[0].set_xlabel('False Positive Rate')\n",
        "        axes[0].set_ylabel('True Positive Rate')\n",
        "        axes[0].set_title(f'{model_name} - ROC Curve')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "    except Exception as e:\n",
        "        axes[0].text(0.5, 0.5, f'ROC Curve Error: {str(e)}', ha='center', va='center')\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    try:\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "        pr_auc = average_precision_score(y_true, y_pred_proba)\n",
        "\n",
        "        axes[1].plot(recall, precision, linewidth=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
        "        axes[1].axhline(y=np.mean(y_true), color='k', linestyle='--', linewidth=1,\n",
        "                       label=f'Baseline (Fraud Rate = {np.mean(y_true):.3f})')\n",
        "        axes[1].set_xlabel('Recall')\n",
        "        axes[1].set_ylabel('Precision')\n",
        "        axes[1].set_title(f'{model_name} - Precision-Recall Curve')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    except Exception as e:\n",
        "        axes[1].text(0.5, 0.5, f'PR Curve Error: {str(e)}', ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{save_dir}{model_name}_roc_pr_curves.png\", dpi=300, bbox_inches='tight')\n",
        "        plots_generated.append(f\"{model_name}_roc_pr_curves.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Probability Distribution Plots\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Histogram of probabilities by class\n",
        "    fraud_probs = y_pred_proba[y_true == 1]\n",
        "    non_fraud_probs = y_pred_proba[y_true == 0]\n",
        "\n",
        "    axes[0].hist(non_fraud_probs, bins=50, alpha=0.7, label='Non-Fraud', color='blue', density=True)\n",
        "    axes[0].hist(fraud_probs, bins=50, alpha=0.7, label='Fraud', color='red', density=True)\n",
        "    axes[0].set_xlabel('Predicted Probability')\n",
        "    axes[0].set_ylabel('Density')\n",
        "    axes[0].set_title(f'{model_name} - Probability Distribution by Class')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Box plot of probabilities by class\n",
        "    prob_data = [non_fraud_probs, fraud_probs]\n",
        "    axes[1].boxplot(prob_data, labels=class_names)\n",
        "    axes[1].set_ylabel('Predicted Probability')\n",
        "    axes[1].set_title(f'{model_name} - Probability Distribution (Box Plot)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{save_dir}{model_name}_probability_distributions.png\", dpi=300, bbox_inches='tight')\n",
        "        plots_generated.append(f\"{model_name}_probability_distributions.png\")\n",
        "    plt.show()\n",
        "\n",
        "    return plots_generated\n",
        "\n",
        "\n",
        "def extract_feature_importance(model, feature_names: list) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extract feature importance from the model if available.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "        elif hasattr(model, 'coef_'):\n",
        "            importances = np.abs(model.coef_[0])\n",
        "        else:\n",
        "            return {'error': 'No feature importance available'}\n",
        "\n",
        "        # Create feature importance dataframe\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': importances\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        # Get top features\n",
        "        top_features = importance_df.head(10).to_dict('records')\n",
        "\n",
        "        return {\n",
        "            'all_features': importance_df.to_dict('records'),\n",
        "            'top_10_features': top_features,\n",
        "            'total_features': len(feature_names)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'error': f'Error extracting feature importance: {str(e)}'}\n",
        "\n",
        "\n",
        "def generate_summary_report(results: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a human-readable summary report.\n",
        "    \"\"\"\n",
        "\n",
        "    basic_metrics = results.get('basic_metrics', {})\n",
        "    fraud_metrics = results.get('fraud_metrics', {})\n",
        "    class_dist = results.get('class_distribution', {})\n",
        "\n",
        "    report = f\"\"\"\n",
        "FRAUD DETECTION MODEL EVALUATION REPORT\n",
        "{'='*60}\n",
        "\n",
        "Model: {results.get('model_name', 'Unknown')}\n",
        "Test Set Size: {results.get('test_set_size', 'Unknown'):,} samples\n",
        "Evaluation Date: {results.get('evaluation_timestamp', 'Unknown')}\n",
        "\n",
        "PERFORMANCE SUMMARY\n",
        "{'-'*30}\n",
        " Overall Accuracy: {basic_metrics.get('accuracy', 0):.3f} ({basic_metrics.get('accuracy', 0)*100:.1f}%)\n",
        " Balanced Accuracy: {basic_metrics.get('balanced_accuracy', 0):.3f}\n",
        " ROC-AUC Score: {basic_metrics.get('roc_auc', 0):.3f}\n",
        " PR-AUC Score: {basic_metrics.get('pr_auc', 0):.3f}\n",
        "\n",
        "FRAUD DETECTION PERFORMANCE\n",
        "{'-'*30}\n",
        " Fraud Detection Rate (Recall): {fraud_metrics.get('fraud_detection_rate', 0):.3f} ({fraud_metrics.get('fraud_detection_rate', 0)*100:.1f}%)\n",
        " Fraud Precision: {fraud_metrics.get('fraud_precision', 0):.3f} ({fraud_metrics.get('fraud_precision', 0)*100:.1f}%)\n",
        " F1-Score: {basic_metrics.get('f1_score', 0):.3f}\n",
        " False Positive Rate: {fraud_metrics.get('false_positive_rate', 0):.3f} ({fraud_metrics.get('false_positive_rate', 0)*100:.1f}%)\n",
        "\n",
        "FRAUD CASES ANALYSIS\n",
        "{'-'*30}\n",
        " Total Fraud Cases: {fraud_metrics.get('fraud_cases_total', 0):,}\n",
        " Fraud Cases Detected: {fraud_metrics.get('fraud_cases_detected', 0):,}\n",
        " Fraud Cases Missed: {fraud_metrics.get('fraud_cases_missed', 0):,}\n",
        " Fraud Rate in Test Set: {class_dist.get('test_set', {}).get('fraud_percentage', 0):.2f}%\n",
        "\n",
        "DETAILED CLASSIFICATION REPORT\n",
        "{'-'*30}\"\"\"\n",
        "\n",
        "    # Add classification report to summary if available\n",
        "    class_report = results.get('classification_report', {})\n",
        "    if class_report:\n",
        "        report += f\"\"\"\n",
        "Class-wise Performance:\n",
        " Non-Fraud: Precision={class_report.get('Non-Fraud', {}).get('precision', 0):.3f}, Recall={class_report.get('Non-Fraud', {}).get('recall', 0):.3f}, F1={class_report.get('Non-Fraud', {}).get('f1-score', 0):.3f}\n",
        " Fraud: Precision={class_report.get('Fraud', {}).get('precision', 0):.3f}, Recall={class_report.get('Fraud', {}).get('recall', 0):.3f}, F1={class_report.get('Fraud', {}).get('f1-score', 0):.3f}\n",
        " Weighted Average: Precision={class_report.get('weighted avg', {}).get('precision', 0):.3f}, Recall={class_report.get('weighted avg', {}).get('recall', 0):.3f}, F1={class_report.get('weighted avg', {}).get('f1-score', 0):.3f}\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\\n{'='*60}\"\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "def save_evaluation_results(results: Dict[str, Any], save_dir: str, model_name: str):\n",
        "    \"\"\"\n",
        "    Save evaluation results to JSON file.\n",
        "    \"\"\"\n",
        "\n",
        "    import os\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Save complete results\n",
        "    results_file = f\"{save_dir}{model_name}_evaluation_results.json\"\n",
        "    with open(results_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save summary report\n",
        "    summary_file = f\"{save_dir}{model_name}_evaluation_summary.txt\"\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(results.get('summary_report', ''))\n",
        "\n",
        "    print(f\"Results saved to: {results_file}\")\n",
        "    print(f\"Summary saved to: {summary_file}\")\n",
        "\n",
        "\n",
        "def print_evaluation_summary(results: Dict[str, Any]):\n",
        "    \"\"\"\n",
        "    Print a formatted summary of the evaluation results.\n",
        "    \"\"\"\n",
        "\n",
        "    print(results.get('summary_report', 'No summary available'))\n",
        "\n",
        "def test_ft_transformer_model(ft_model, X_test_num, X_test_cat, y_test, feature_names=None, plot_results=False, detailed_report=False):\n",
        "    \"\"\"\n",
        "    Convenience function specifically for testing FT-Transformer models.\n",
        "\n",
        "    Usage:\n",
        "        results = test_ft_transformer_model(ft_model, X_test_num, X_test_cat, y_test, feature_names)\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a wrapper class for FT-Transformer to match the expected interface\n",
        "    class FTTransformerWrapper:\n",
        "        def __init__(self, ft_model):\n",
        "            self.ft_model = ft_model\n",
        "\n",
        "        def predict_proba(self, X_test):\n",
        "            # Assuming X_test is a tuple of (X_num, X_cat)\n",
        "            if isinstance(X_test, tuple):\n",
        "                X_num, X_cat = X_test\n",
        "            else:\n",
        "                # If single array, need to split appropriately\n",
        "                raise ValueError(\"FT-Transformer requires separate numerical and categorical inputs\")\n",
        "\n",
        "            if len(categorical_cols) > 0:\n",
        "                return self.ft_model.predict_proba_cat(X_num, X_cat)\n",
        "            else:\n",
        "                return self.ft_model.predict_proba(X_num)\n",
        "\n",
        "        def predict(self, X_test):\n",
        "            proba = self.predict_proba(X_test)\n",
        "            return (proba[:, 1] >= 0.95).astype(int)\n",
        "\n",
        "    wrapper = FTTransformerWrapper(ft_model)\n",
        "\n",
        "    return comprehensive_model_test(\n",
        "        model=wrapper,\n",
        "        X_test=(X_test_num, X_test_cat),\n",
        "        y_test=y_test,\n",
        "        model_name=\"FTTransformer_Fraud_Classifier\",\n",
        "        feature_names=feature_names,\n",
        "        class_names=['Non-Fraud', 'Fraud'],\n",
        "        threshold=0.85,\n",
        "        save_results=False,\n",
        "        results_dir=\"../results/\",\n",
        "        plot_results=plot_results,\n",
        "        detailed_report=detailed_report\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LEutgniy_3PB"
      },
      "outputs": [],
      "source": [
        "class FraudFTTransformer:\n",
        "    def __init__(self, n_num_features, n_cat_features, n_cont_features, cat_cardinalities,\n",
        "                 device=None, seed: int = 42, **model_params):\n",
        "        # Use global device if not specified\n",
        "        if device is None:\n",
        "            device = globals().get('device', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "        self.device = device\n",
        "        self.seed = seed\n",
        "\n",
        "        # Set seeds for reproducibility across libs\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "\n",
        "        print(f\"Initializing FraudFTTransformer on device: {self.device}\")\n",
        "\n",
        "        default_params = {\n",
        "            'n_blocks':3,\n",
        "            'd_block': 224,\n",
        "            'attention_n_heads': 8,\n",
        "            'attention_dropout': 0.1,\n",
        "            'ffn_d_hidden': None,\n",
        "            'ffn_d_hidden_multiplier': 5/4,\n",
        "            'ffn_dropout': 0.1,\n",
        "            'residual_dropout': 0.0,\n",
        "        }\n",
        "\n",
        "        # Update with provided parameters\n",
        "        default_params.update(model_params)\n",
        "        self.model_params = default_params\n",
        "\n",
        "        print(f\"Model parameters: {self.model_params}\")\n",
        "\n",
        "        # Model configuration optimized for fraud detection\n",
        "        self.model = FTTransformer(\n",
        "            n_cont_features=n_cont_features,\n",
        "            cat_cardinalities=cat_cardinalities,\n",
        "            d_out=2,\n",
        "            **default_params\n",
        "        ).to(self.device)\n",
        "\n",
        "        fraud_count = (y_train_split == 1).sum()\n",
        "        non_fraud_count = (y_train_split == 0).sum()\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
        "\n",
        "        self.optimizer = optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=0.0003,\n",
        "            weight_decay=1e-3\n",
        "        )\n",
        "\n",
        "        # Ensure DataLoader worker determinism - use CPU generator for reproducibility\n",
        "        self.generator = torch.Generator().manual_seed(self.seed)\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='min', patience=5, factor=0.7, min_lr=1e-6\n",
        "        )\n",
        "\n",
        "        # Print model info\n",
        "        total_params = sum(p.numel() for p in self.model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        print(f\"Model parameters: {total_params:,} total, {trainable_params:,} trainable\")\n",
        "\n",
        "        if torch.cuda.is_available() and self.device.type == 'cuda':\n",
        "            print(f\"GPU memory allocated: {torch.cuda.memory_allocated(self.device) / 1024**2:.1f} MB\")\n",
        "\n",
        "\n",
        "    def fit(self, X_num, y, X_val_num=None, y_val=None,\n",
        "            epochs=100, batch_size=512, patience=20):\n",
        "\n",
        "        X_cat = None\n",
        "\n",
        "        pin_memory = torch.cuda.is_available() and self.device.type == 'cuda'\n",
        "        # Use num_workers=0 in Jupyter to avoid multiprocessing issues\n",
        "        num_workers = 0\n",
        "\n",
        "        print(f\"DataLoader config: pin_memory={pin_memory}, num_workers={num_workers}\")\n",
        "\n",
        "        # Create data loaders with CUDA optimizations\n",
        "        train_dataset = TensorDataset(\n",
        "            torch.FloatTensor(X_num),\n",
        "            torch.LongTensor(y)\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            generator=self.generator,\n",
        "            pin_memory=pin_memory,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "\n",
        "        if X_val_num is not None:\n",
        "            val_dataset = TensorDataset(\n",
        "                torch.FloatTensor(X_val_num),\n",
        "                torch.LongTensor(y_val)\n",
        "            )\n",
        "\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                batch_size=batch_size,\n",
        "                pin_memory=pin_memory,\n",
        "                num_workers=num_workers\n",
        "            )\n",
        "\n",
        "        # Training loop\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        history = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_auc': [], 'val_accuracy': []}\n",
        "\n",
        "        print(f\"Starting training for {epochs} epochs on {self.device}\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            train_loss = 0\n",
        "\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for batch_idx, (batch_num, batch_y) in enumerate(train_loader):\n",
        "                # Move tensors to device with non_blocking for CUDA efficiency\n",
        "                batch_num = batch_num.to(self.device, non_blocking=True)\n",
        "                batch_y = batch_y.to(self.device, non_blocking=True)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_num, None)\n",
        "                loss = self.criterion(outputs, batch_y.squeeze())\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping for stability\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                # Calculate training accuracy\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                train_total += batch_y.size(0)\n",
        "                train_correct += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "                # Clear cache periodically on CUDA to prevent memory issues\n",
        "                if torch.cuda.is_available() and batch_idx % 100 == 0:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            # Calculate and store training accuracy\n",
        "            train_accuracy = train_correct / train_total\n",
        "            history['train_accuracy'].append(train_accuracy)\n",
        "\n",
        "            # Validation phase\n",
        "            if X_val_num is not None:\n",
        "                val_loss, val_auc, val_accuracy = self._validate(val_loader)\n",
        "                history['val_loss'].append(val_loss)\n",
        "                history['val_auc'].append(val_auc)\n",
        "                history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "                # Learning rate scheduling\n",
        "                self.scheduler.step(val_loss)\n",
        "\n",
        "                # Early stopping tracking\n",
        "                improved = val_loss < best_val_loss\n",
        "                if improved:\n",
        "                    best_val_loss = val_loss\n",
        "                    patience_counter = 0\n",
        "                    # Save a deep copy of the best state dict\n",
        "                    best_state_dict = copy.deepcopy(self.model.state_dict())\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "                # Print statement with accuracy\n",
        "                print(f\"Epoch {epoch}: Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_accuracy:.4f} | \"\n",
        "                      f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "            history['train_loss'].append(train_loss/len(train_loader))\n",
        "\n",
        "        # Restore best model weights if available\n",
        "        if 'best_state_dict' in locals() and best_state_dict is not None:\n",
        "            self.model.load_state_dict(best_state_dict)\n",
        "            self.best_val_loss = best_val_loss\n",
        "            self.best_state_dict = best_state_dict\n",
        "        else:\n",
        "            print(\"No validation data provided - using final model weights\")\n",
        "            self.best_val_loss = None\n",
        "            self.best_state_dict = None\n",
        "\n",
        "        return history\n",
        "\n",
        "    def _validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        val_loss = 0\n",
        "        all_probs = []\n",
        "        all_labels = []\n",
        "\n",
        "        # Track validation accuracy\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_num, batch_y in val_loader:\n",
        "                # Move tensors to device with non_blocking for CUDA efficiency\n",
        "                batch_num = batch_num.to(self.device, non_blocking=True)\n",
        "                batch_y = batch_y.to(self.device, non_blocking=True)\n",
        "\n",
        "                outputs = self.model(batch_num, None)\n",
        "                loss = self.criterion(outputs, batch_y.squeeze())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "                all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += batch_y.size(0)\n",
        "                val_correct += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_auc = roc_auc_score(all_labels, all_probs)\n",
        "        return val_loss/len(val_loader), val_auc, val_accuracy\n",
        "\n",
        "    def predict_proba(self, X_num, batch_size=512):\n",
        "        self.model.eval()\n",
        "        all_probs = []\n",
        "\n",
        "        # CUDA optimizations for inference\n",
        "        pin_memory = torch.cuda.is_available() and self.device.type == 'cuda'\n",
        "\n",
        "        dataset = TensorDataset(\n",
        "            torch.FloatTensor(X_num)\n",
        "        )\n",
        "        loader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            pin_memory=pin_memory,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                batch_num = batch[0].to(self.device, non_blocking=True)\n",
        "\n",
        "                outputs = self.model(batch_num, None)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        return np.array(all_probs)\n",
        "\n",
        "    def get_memory_usage(self):\n",
        "        \"\"\"Get current memory usage information\"\"\"\n",
        "        if torch.cuda.is_available() and self.device.type == 'cuda':\n",
        "            allocated = torch.cuda.memory_allocated(self.device) / 1024**2\n",
        "            cached = torch.cuda.memory_reserved(self.device) / 1024**2\n",
        "            return f\"GPU Memory - Allocated: {allocated:.1f} MB, Cached: {cached:.1f} MB\"\n",
        "        else:\n",
        "            return \"CPU mode - no GPU memory tracking\"\n",
        "\n",
        "    def cleanup_memory(self):\n",
        "        \"\"\"Clean up CUDA memory and force garbage collection\"\"\"\n",
        "        import gc\n",
        "\n",
        "        # Force garbage collection to clean up any lingering DataLoader references\n",
        "        gc.collect()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"CUDA cache cleared\")\n",
        "\n",
        "        print(\"Memory cleanup completed\")\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the best model state and configuration\"\"\"\n",
        "        save_dict = {\n",
        "            'model_state_dict': self.best_state_dict if hasattr(self, 'best_state_dict') and self.best_state_dict is not None else self.model.state_dict(),\n",
        "            'model_params': self.model_params,\n",
        "            'best_val_loss': getattr(self, 'best_val_loss', None),\n",
        "            'device': str(self.device),\n",
        "            'seed': self.seed\n",
        "        }\n",
        "        torch.save(save_dict, filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load model state and configuration\"\"\"\n",
        "        checkpoint = torch.load(filepath, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.best_val_loss = checkpoint.get('best_val_loss', None)\n",
        "        self.best_state_dict = checkpoint['model_state_dict']\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        if self.best_val_loss is not None:\n",
        "            print(f\"Best validation loss: {self.best_val_loss:.4f}\")\n",
        "\n",
        "    def ensure_best_model(self):\n",
        "        \"\"\"Ensure the model is using the best weights\"\"\"\n",
        "        if hasattr(self, 'best_state_dict') and self.best_state_dict is not None:\n",
        "            self.model.load_state_dict(self.best_state_dict)\n",
        "            print(\"Using best model weights for evaluation\")\n",
        "        else:\n",
        "            print(\"No best model weights available, using current weights\")\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training and validation metrics\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    print(history)\n",
        "    # Plot loss\n",
        "    epochs = range(1, len(history['val_auc']) + 1)\n",
        "\n",
        "    # axes[0].plot(epochs, history['train_auc'], 'b-', label='Training AUC', linewidth=2)\n",
        "    axes[0].plot(epochs, history['val_auc'], 'r-', label='Validation AUC', linewidth=2)\n",
        "    axes[0].set_title('Model AUC During Training')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('AUC')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot accuracy\n",
        "    # axes[1].plot(epochs, history['train_accuracy'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    axes[1].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    axes[1].set_title('Model Loss During Training')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the FT-Transformer and evaluate performance"
      ],
      "metadata": {
        "id": "B2hd9bqbqez1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage - model will automatically use the global device (CUDA if available)\n",
        "ft_model = FraudFTTransformer(\n",
        "    n_num_features=len(feature_names),\n",
        "    n_cat_features=len(categorical_cols),\n",
        "    n_cont_features=len(numerical_cols),\n",
        "    cat_cardinalities=cat_dims,\n",
        "    device=device,\n",
        "    seed=random_seed\n",
        ")\n",
        "\n",
        "# Optimize batch size based on device\n",
        "if torch.cuda.is_available() and device.type == 'cuda':\n",
        "    # Larger batch size for CUDA\n",
        "    batch_size = 4096\n",
        "    print(f\"Using CUDA optimized batch size: {batch_size}\")\n",
        "else:\n",
        "    # Smaller batch size for CPU\n",
        "    batch_size = 1024\n",
        "    print(f\"Using CPU batch size: {batch_size}\")\n",
        "\n",
        "print(f\"{ft_model.get_memory_usage()}\")\n",
        "\n",
        "# Train the model\n",
        "history = ft_model.fit(\n",
        "    X_train_num, y_train,\n",
        "    X_val_num, y_val_val,\n",
        "    epochs=35, batch_size=batch_size, patience=10\n",
        ")\n",
        "\n",
        "# Clean up memory after training\n",
        "ft_model.cleanup_memory()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# Ensure we're using the best model for evaluation\n",
        "print(\"Preparing for evaluation with the best model...\")\n",
        "ft_model.ensure_best_model()\n",
        "\n",
        "# Verify model state\n",
        "if hasattr(ft_model, 'best_val_loss') and ft_model.best_val_loss is not None:\n",
        "    print(f\"Using best model with validation loss: {ft_model.best_val_loss:.4f}\")\n",
        "else:\n",
        "    print(\"Using current model weights (no validation-based best model available)\")\n",
        "\n",
        "print(f\"Model memory usage: {ft_model.get_memory_usage()}\")\n",
        "print(\"Ready for test set evaluation!\")\n",
        "\n",
        "print(\"Model Evaluation Utilities\")\n",
        "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
        "X_test_num = X_test[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "X_test_cat = X_test[categorical_cols].reset_index(drop=True).to_numpy()\n",
        "results = test_ft_transformer_model(ft_model, X_test_num, X_test_cat, y_test, feature_names, True, True)\n",
        "\n"
      ],
      "metadata": {
        "id": "3z7HXR3MnhRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate FT-Transformer over different seed values"
      ],
      "metadata": {
        "id": "2iK_KrcTqmtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_results = {\n",
        "    'sum_precision': 0,\n",
        "    'sum_recall': 0,\n",
        "    'sum_f1_score': 0,\n",
        "    'sum_accuracy': 0,\n",
        "    'sum_pr_auc': 0\n",
        "}\n",
        "seeds = [10, 20, 30, 40, 50]\n",
        "\n",
        "X_train_num = X_train_split[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "y_train = y_train_split.reset_index(drop=True).to_numpy()\n",
        "\n",
        "X_val_num = X_val[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "y_val_val = y_val.reset_index(drop=True).to_numpy()\n",
        "\n",
        "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
        "X_test_num = X_test[numerical_cols].reset_index(drop=True).to_numpy()\n",
        "X_test_cat = X_test[categorical_cols].reset_index(drop=True).to_numpy()\n",
        "\n",
        "categorical_cols = []\n",
        "cat_dims = []\n",
        "\n",
        "for seed in seeds:\n",
        "  random_seed = seed\n",
        "    # Usage - model will automatically use the global device (CUDA if available)\n",
        "  ft_model = FraudFTTransformer(\n",
        "    n_num_features=len(feature_names),\n",
        "    n_cat_features=len(categorical_cols),\n",
        "    n_cont_features=len(numerical_cols),\n",
        "    cat_cardinalities=cat_dims,\n",
        "    device=device,\n",
        "    seed=seed\n",
        "  )\n",
        "\n",
        "# Optimize batch size based on device\n",
        "  if torch.cuda.is_available() and device.type == 'cuda':\n",
        "    # Larger batch size for CUDA\n",
        "    batch_size = 4096\n",
        "    print(f\"Using CUDA optimized batch size: {batch_size}\")\n",
        "  else:\n",
        "    # Smaller batch size for CPU\n",
        "    batch_size = 1024\n",
        "    print(f\"Using CPU batch size: {batch_size}\")\n",
        "\n",
        "  print(f\"{ft_model.get_memory_usage()}\")\n",
        "\n",
        "# Train the model\n",
        "  history = ft_model.fit(\n",
        "    X_train_num, y_train,\n",
        "    X_val_num, y_val_val,\n",
        "    epochs=35,\n",
        "    batch_size=batch_size,\n",
        "    patience=10 )\n",
        "\n",
        "  results = test_ft_transformer_model(ft_model, X_test_num, X_test_cat, y_test, feature_names)\n",
        "\n",
        "  average_results['sum_precision'] = average_results['sum_precision'] + results['basic_metrics']['precision']\n",
        "  average_results['sum_recall'] = average_results['sum_recall'] + results['basic_metrics']['recall']\n",
        "  average_results['sum_f1_score'] = average_results['sum_f1_score'] + results['basic_metrics']['f1_score']\n",
        "  average_results['sum_accuracy'] = average_results['sum_accuracy'] + results['basic_metrics']['accuracy']\n",
        "  average_results['sum_pr_auc'] = average_results['sum_pr_auc'] + int(results['basic_metrics']['pr_auc'])\n",
        "\n",
        "print(f\"Average Precision: {average_results['sum_precision']/len(seeds)}\")\n",
        "print(f\"Average Recall: {average_results['sum_recall']/len(seeds)}\")\n",
        "print(f\"Average F1 Score: {average_results['sum_f1_score']/len(seeds)}\")\n",
        "print(f\"Average Accuracy: {average_results['sum_accuracy']/len(seeds)}\")\n",
        "print(f\"Average PR-AUC: {average_results['sum_pr_auc']/len(seeds)}\")\n",
        ""
      ],
      "metadata": {
        "id": "Iu2sTlxtkPZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftK5V4uP_3PG"
      },
      "source": [
        "## 8. Explainable AI (XAI) with SHAP\n",
        "\n",
        "This section uses SHAP (SHapley Additive exPlanations) to explain the FT-Transformer's predictions:\n",
        "- Global explanations: overall feature impact via summary plots\n",
        "- Local explanations: per-transaction explanations for specific predictions\n",
        "\n",
        "Notes:\n",
        "- We explain the probability of the positive class (Fraud)\n",
        "- We use a small background sample for KernelExplainer efficiency\n",
        "- Features are numerical and standardized; we map indices back to `feature_names`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INRuPJpd_3PG"
      },
      "outputs": [],
      "source": [
        "# SHAP explanations for FT-Transformer\n",
        "import shap\n",
        "\n",
        "# Ensure we have numpy arrays for SHAP\n",
        "X_train_array = X_train_num  # already numpy\n",
        "X_test_array = X_test_num\n",
        "\n",
        "# Define a prediction function that returns P(class=1)\n",
        "def predict_proba_pos(X):\n",
        "    # X expected as numpy array\n",
        "    # Ensure we're in evaluation mode and handle device properly\n",
        "    ft_model.model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = ft_model.predict_proba(X)\n",
        "        if probs.ndim == 2 and probs.shape[1] == 2:\n",
        "            return probs[:, 1]\n",
        "        return probs.reshape(-1)\n",
        "\n",
        "# Background sample for KernelExplainer (keep small for speed)\n",
        "background_size = min(200, X_train_array.shape[0])\n",
        "rng = np.random.default_rng(random_seed)\n",
        "background_idx = rng.choice(X_train_array.shape[0], size=background_size, replace=False)\n",
        "background = X_train_array[background_idx]\n",
        "\n",
        "# Select a manageable test subset for visualization\n",
        "explain_size = min(500, X_test_array.shape[0])\n",
        "explain_idx = rng.choice(X_test_array.shape[0], size=explain_size, replace=False)\n",
        "X_explain = X_test_array[explain_idx]\n",
        "y_explain = y_test[explain_idx]\n",
        "\n",
        "# Build SHAP explainer\n",
        "explainer = shap.KernelExplainer(model=predict_proba_pos, data=background, link=\"logit\")\n",
        "\n",
        "# Compute SHAP values (probability output)\n",
        "# nsamples='auto' balances speed and accuracy\n",
        "shap_values = explainer.shap_values(X_explain, nsamples='auto')\n",
        "\n",
        "# Convert to numpy array if needed\n",
        "shap_values = np.array(shap_values)\n",
        "if shap_values.ndim == 3:\n",
        "    # KernelExplainer can return list per class; we used link=logit + scalar output, but guard anyway\n",
        "    shap_values = shap_values[1]\n",
        "\n",
        "# Summary plots\n",
        "plt.figure(figsize=(10, 5))\n",
        "shap.summary_plot(shap_values, X_explain, feature_names=feature_names, show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "shap.summary_plot(shap_values, X_explain, feature_names=feature_names, plot_type='bar', show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Local explanations for a few samples\n",
        "num_local = 3\n",
        "local_idx = rng.choice(X_explain.shape[0], size=num_local, replace=False)\n",
        "for i, idx in enumerate(local_idx, 1):\n",
        "    x = X_explain[idx]\n",
        "    sv = shap_values[idx]\n",
        "    prob = float(predict_proba_pos(x.reshape(1, -1))[0])\n",
        "    print(f\"\\n=== Local explanation {i} ===\")\n",
        "    print(f\"True label: {'Fraud' if y_explain[idx]==1 else 'Non-Fraud'} | Pred P(Fraud): {prob:.4f}\")\n",
        "    shap.force_plot(explainer.expected_value, sv, x, feature_names=feature_names, matplotlib=True)\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}