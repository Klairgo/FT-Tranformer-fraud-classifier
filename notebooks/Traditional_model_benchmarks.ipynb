{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2RrTHhcvcFP"
      },
      "source": [
        "# Dataset2 Model Benchmarks\n",
        "\n",
        "This notebook evaluates multiple classical and neural classifiers on Dataset2 using the preprocessed train/test CSVs.\n",
        "\n",
        "Models included:\n",
        "- Logistic Regression (balanced)\n",
        "- Decision Tree (balanced)\n",
        "- Random Forest (balanced)\n",
        "- Gradient Boosting\n",
        "- Linear SVM (balanced)\n",
        "- MLPClassifier (neural network)\n",
        "\n",
        "For each model, we compute:\n",
        "- Accuracy, Precision, Recall, F1\n",
        "- ROC-AUC, PR-AUC\n",
        "- Confusion Matrix\n",
        "- Classification Report\n",
        "\n",
        "All results are summarized for easy comparison with your FT-Transformer.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ndSqpU4wvnGq",
        "outputId": "11addae3-56cf-4c5a-e235-845fad662efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kUgW3LP9vcFR"
      },
      "outputs": [],
      "source": [
        "# Paths and configuration\n",
        "train_dataset_path = '../data/train.csv'\n",
        "test_dataset_path = '../data/test.csv'\n",
        "metadata_path = '../data/preprocessing_metadata.json'\n",
        "class_label = 'Class'\n",
        "random_seed = 30\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pgGm5CKnvcFR"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qmw-Wp4BvcFR",
        "outputId": "48681c34-4da0-4f3b-d46a-c2dc42f927d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Dataset...\n",
            "(409412, 31) (28481, 31)\n",
            "Train: (409412, 30), Test: (28481, 30)\n",
            "Class balance (train): [255883 153529]\n",
            "Class balance (test): [28432    49]\n"
          ]
        }
      ],
      "source": [
        "print('Loading Dataset...')\n",
        "train_df = pd.read_csv(train_dataset_path)\n",
        "test_df = pd.read_csv(test_dataset_path)\n",
        "print(train_df.shape, test_df.shape)\n",
        "\n",
        "# Identify features/target\n",
        "feature_cols = [c for c in train_df.columns if c != class_label]\n",
        "X_train = train_df[feature_cols].copy()\n",
        "y_train = train_df[class_label].astype(int).values\n",
        "X_test = test_df[feature_cols].copy()\n",
        "y_test = test_df[class_label].astype(int).values\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "print('Class balance (train):', np.bincount(y_train))\n",
        "print('Class balance (test):', np.bincount(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-f0hWBrXvcFS"
      },
      "outputs": [],
      "source": [
        "# Utility: evaluate model\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def format_classification_report_latex(y_true, y_pred, class_names=(\"Non-Fraud\", \"Fraud\"), digits: int = 4) -> str:\n",
        "    \"\"\"Return a LaTeX table for the classification report matching the requested template.\"\"\"\n",
        "    rep = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=list(class_names),\n",
        "        output_dict=True,\n",
        "        zero_division=0,\n",
        "        digits=digits,\n",
        "    )\n",
        "\n",
        "    def fmt(x: float) -> str:\n",
        "        return f\"{x:.{digits}f}\"\n",
        "\n",
        "    non_fraud = rep[class_names[0]]\n",
        "    fraud = rep[class_names[1]]\n",
        "    accuracy_val = rep[\"accuracy\"]\n",
        "    macro_avg = rep[\"macro avg\"]\n",
        "    weighted_avg = rep[\"weighted avg\"]\n",
        "    total_support = int(non_fraud[\"support\"] + fraud[\"support\"])\n",
        "\n",
        "    lines = []\n",
        "    lines.append(r\"\\begin{table}[h!]\")\n",
        "    lines.append(r\"\\centering\")\n",
        "    lines.append(r\"\\begin{tabular}{lcccc}\")\n",
        "    lines.append(r\"\\hline\")\n",
        "    lines.append(r\"\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\")\n",
        "    lines.append(r\"\\hline\")\n",
        "    lines.append(f\"Non-Fraud      & {fmt(non_fraud['precision'])} & {fmt(non_fraud['recall'])} & {fmt(non_fraud['f1-score'])} & {int(non_fraud['support'])} \\\\\\\\\")\n",
        "    lines.append(f\"Fraud          & {fmt(fraud['precision'])} & {fmt(fraud['recall'])} & {fmt(fraud['f1-score'])} & {int(fraud['support'])} \\\\\\\\\")\n",
        "    lines.append(r\"\\hline\")\n",
        "    lines.append(f\"Accuracy       &        &        & {fmt(accuracy_val)} & {total_support} \\\\\\\\\")\n",
        "    lines.append(f\"Macro Avg      & {fmt(macro_avg['precision'])} & {fmt(macro_avg['recall'])} & {fmt(macro_avg['f1-score'])} & {total_support} \\\\\\\\\")\n",
        "    lines.append(f\"Weighted Avg   & {fmt(weighted_avg['precision'])} & {fmt(weighted_avg['recall'])} & {fmt(weighted_avg['f1-score'])} & {total_support} \\\\\\\\\")\n",
        "    lines.append(r\"\\hline\")\n",
        "    lines.append(r\"\\end{tabular}\")\n",
        "    lines.append(r\"\\caption{Classification Report}\")\n",
        "    lines.append(r\"\\label{tab:classification_report}\")\n",
        "    lines.append(r\"\\end{table}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def evaluate_classifier(model, X_test, y_test, name: str) -> Dict:\n",
        "    y_pred = model.predict(X_test)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    elif hasattr(model, 'decision_function'):\n",
        "        # For LinearSVC\n",
        "        scores = model.decision_function(X_test)\n",
        "        # Convert scores to [0,1] via min-max for AUC/PR (ranking is what matters)\n",
        "        scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
        "        y_pred_proba = scores\n",
        "    else:\n",
        "        y_pred_proba = (y_pred == 1).astype(float)\n",
        "\n",
        "    metrics = {\n",
        "        'model': name,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
        "        'pr_auc': average_precision_score(y_test, y_pred_proba),\n",
        "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f} | Precision: {metrics['precision']:.4f} | Recall: {metrics['recall']:.4f} | F1: {metrics['f1']:.4f}\")\n",
        "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} | PR-AUC: {metrics['pr_auc']:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])\n",
        "\n",
        "    # Print LaTeX-formatted classification report and save alongside results for easy copy/paste\n",
        "    latex_report = format_classification_report_latex(y_test, y_pred, class_names=(\"Non-Fraud\", \"Fraud\"), digits=4)\n",
        "    print(\"\\nLaTeX Classification Report:\\n\")\n",
        "    print(latex_report)\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FQKmvTBuvcFS"
      },
      "outputs": [],
      "source": [
        "# Define models\n",
        "models = []\n",
        "\n",
        "# Logistic Regression (balanced)\n",
        "models.append(('LogisticRegression', LogisticRegression(max_iter=100000, class_weight='balanced', n_jobs=None)))\n",
        "\n",
        "# # Decision Tree (balanced)\n",
        "models.append(('DecisionTree-10', DecisionTreeClassifier(class_weight='balanced', random_state=10)))\n",
        "models.append(('DecisionTree-30', DecisionTreeClassifier(class_weight='balanced', random_state=30)))\n",
        "models.append(('DecisionTree-50', DecisionTreeClassifier(class_weight='balanced', random_state=50)))\n",
        "\n",
        "# Random Forest (balanced)\n",
        "models.append(('RandomForest-10', RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=10)))\n",
        "models.append(('RandomForest-30', RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=30)))\n",
        "models.append(('RandomForest-50', RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=50)))\n",
        "\n",
        "# # Gradient Boosting\n",
        "models.append(('GradientBoosting-10', GradientBoostingClassifier(random_state=10)))\n",
        "models.append(('GradientBoosting-30', GradientBoostingClassifier(random_state=30)))\n",
        "models.append(('GradientBoosting-50', GradientBoostingClassifier(random_state=50)))\n",
        "\n",
        "\n",
        "# # Linear SVM (use LinearSVC, which does not output proba)\n",
        "models.append(('LinearSVM-10', LinearSVC(class_weight='balanced', random_state=10)))\n",
        "models.append(('LinearSVM-30', LinearSVC(class_weight='balanced', random_state=30)))\n",
        "models.append(('LinearSVM-50', LinearSVC(class_weight='balanced', random_state=50)))\n",
        "\n",
        "# MLP (neural network)\n",
        "models.append(('MLP-10', MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', alpha=1e-4,\n",
        "                                    batch_size=2048, learning_rate_init=1e-3, max_iter=50, random_state=10)))\n",
        "models.append(('MLP-30', MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', alpha=1e-4,\n",
        "                                    batch_size=2048, learning_rate_init=1e-3, max_iter=50, random_state=30)))\n",
        "models.append(('MLP-50', MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', alpha=1e-4,\n",
        "                                    batch_size=2048, learning_rate_init=1e-3, max_iter=50, random_state=50)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAR1-kE7vcFT",
        "outputId": "6c94a06a-ac19-4bc4-c0ee-fc4d9ff705e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LogisticRegression...\n",
            "\n",
            "=== LogisticRegression ===\n",
            "Accuracy: 0.9735 | Precision: 0.0566 | Recall: 0.9184 | F1: 0.1066\n",
            "ROC-AUC: 0.9576 | PR-AUC: 0.7161\n",
            "Confusion Matrix:\n",
            " [[27682   750]\n",
            " [    4    45]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9999 & 0.9736 & 0.9866 & 28432 \\\\\n",
            "Fraud          & 0.0566 & 0.9184 & 0.1066 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9735 & 28481 \\\\\n",
            "Macro Avg      & 0.5282 & 0.9460 & 0.5466 & 28481 \\\\\n",
            "Weighted Avg   & 0.9982 & 0.9735 & 0.9851 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training DecisionTree-10...\n",
            "\n",
            "=== DecisionTree-10 ===\n",
            "Accuracy: 0.9974 | Precision: 0.3700 | Recall: 0.7551 | F1: 0.4966\n",
            "ROC-AUC: 0.8764 | PR-AUC: 0.2798\n",
            "Confusion Matrix:\n",
            " [[28369    63]\n",
            " [   12    37]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9996 & 0.9978 & 0.9987 & 28432 \\\\\n",
            "Fraud          & 0.3700 & 0.7551 & 0.4966 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9974 & 28481 \\\\\n",
            "Macro Avg      & 0.6848 & 0.8764 & 0.7477 & 28481 \\\\\n",
            "Weighted Avg   & 0.9985 & 0.9974 & 0.9978 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training DecisionTree-30...\n",
            "\n",
            "=== DecisionTree-30 ===\n",
            "Accuracy: 0.9973 | Precision: 0.3592 | Recall: 0.7551 | F1: 0.4868\n",
            "ROC-AUC: 0.8764 | PR-AUC: 0.2717\n",
            "Confusion Matrix:\n",
            " [[28366    66]\n",
            " [   12    37]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9996 & 0.9977 & 0.9986 & 28432 \\\\\n",
            "Fraud          & 0.3592 & 0.7551 & 0.4868 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9973 & 28481 \\\\\n",
            "Macro Avg      & 0.6794 & 0.8764 & 0.7427 & 28481 \\\\\n",
            "Weighted Avg   & 0.9985 & 0.9973 & 0.9977 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training DecisionTree-50...\n",
            "\n",
            "=== DecisionTree-50 ===\n",
            "Accuracy: 0.9975 | Precision: 0.3838 | Recall: 0.7755 | F1: 0.5135\n",
            "ROC-AUC: 0.8867 | PR-AUC: 0.2981\n",
            "Confusion Matrix:\n",
            " [[28371    61]\n",
            " [   11    38]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9996 & 0.9979 & 0.9987 & 28432 \\\\\n",
            "Fraud          & 0.3838 & 0.7755 & 0.5135 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9975 & 28481 \\\\\n",
            "Macro Avg      & 0.6917 & 0.8867 & 0.7561 & 28481 \\\\\n",
            "Weighted Avg   & 0.9986 & 0.9975 & 0.9979 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training RandomForest-10...\n",
            "\n",
            "=== RandomForest-10 ===\n",
            "Accuracy: 0.9996 | Precision: 0.9302 | Recall: 0.8163 | F1: 0.8696\n",
            "ROC-AUC: 0.9606 | PR-AUC: 0.8750\n",
            "Confusion Matrix:\n",
            " [[28429     3]\n",
            " [    9    40]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9997 & 0.9999 & 0.9998 & 28432 \\\\\n",
            "Fraud          & 0.9302 & 0.8163 & 0.8696 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9996 & 28481 \\\\\n",
            "Macro Avg      & 0.9650 & 0.9081 & 0.9347 & 28481 \\\\\n",
            "Weighted Avg   & 0.9996 & 0.9996 & 0.9996 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training RandomForest-30...\n",
            "\n",
            "=== RandomForest-30 ===\n",
            "Accuracy: 0.9995 | Precision: 0.9091 | Recall: 0.8163 | F1: 0.8602\n",
            "ROC-AUC: 0.9636 | PR-AUC: 0.8747\n",
            "Confusion Matrix:\n",
            " [[28428     4]\n",
            " [    9    40]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9997 & 0.9999 & 0.9998 & 28432 \\\\\n",
            "Fraud          & 0.9091 & 0.8163 & 0.8602 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9995 & 28481 \\\\\n",
            "Macro Avg      & 0.9544 & 0.9081 & 0.9300 & 28481 \\\\\n",
            "Weighted Avg   & 0.9995 & 0.9995 & 0.9995 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training RandomForest-50...\n",
            "\n",
            "=== RandomForest-50 ===\n",
            "Accuracy: 0.9995 | Precision: 0.9091 | Recall: 0.8163 | F1: 0.8602\n",
            "ROC-AUC: 0.9621 | PR-AUC: 0.8742\n",
            "Confusion Matrix:\n",
            " [[28428     4]\n",
            " [    9    40]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9997 & 0.9999 & 0.9998 & 28432 \\\\\n",
            "Fraud          & 0.9091 & 0.8163 & 0.8602 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9995 & 28481 \\\\\n",
            "Macro Avg      & 0.9544 & 0.9081 & 0.9300 & 28481 \\\\\n",
            "Weighted Avg   & 0.9995 & 0.9995 & 0.9995 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training GradientBoosting-10...\n",
            "\n",
            "=== GradientBoosting-10 ===\n",
            "Accuracy: 0.9916 | Precision: 0.1588 | Recall: 0.8980 | F1: 0.2699\n",
            "ROC-AUC: 0.9721 | PR-AUC: 0.6760\n",
            "Confusion Matrix:\n",
            " [[28199   233]\n",
            " [    5    44]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9998 & 0.9918 & 0.9958 & 28432 \\\\\n",
            "Fraud          & 0.1588 & 0.8980 & 0.2699 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9916 & 28481 \\\\\n",
            "Macro Avg      & 0.5793 & 0.9449 & 0.6329 & 28481 \\\\\n",
            "Weighted Avg   & 0.9984 & 0.9916 & 0.9945 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training GradientBoosting-30...\n",
            "\n",
            "=== GradientBoosting-30 ===\n",
            "Accuracy: 0.9916 | Precision: 0.1588 | Recall: 0.8980 | F1: 0.2699\n",
            "ROC-AUC: 0.9721 | PR-AUC: 0.6760\n",
            "Confusion Matrix:\n",
            " [[28199   233]\n",
            " [    5    44]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9998 & 0.9918 & 0.9958 & 28432 \\\\\n",
            "Fraud          & 0.1588 & 0.8980 & 0.2699 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9916 & 28481 \\\\\n",
            "Macro Avg      & 0.5793 & 0.9449 & 0.6329 & 28481 \\\\\n",
            "Weighted Avg   & 0.9984 & 0.9916 & 0.9945 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training GradientBoosting-50...\n",
            "\n",
            "=== GradientBoosting-50 ===\n",
            "Accuracy: 0.9916 | Precision: 0.1588 | Recall: 0.8980 | F1: 0.2699\n",
            "ROC-AUC: 0.9721 | PR-AUC: 0.6760\n",
            "Confusion Matrix:\n",
            " [[28199   233]\n",
            " [    5    44]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9998 & 0.9918 & 0.9958 & 28432 \\\\\n",
            "Fraud          & 0.1588 & 0.8980 & 0.2699 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9916 & 28481 \\\\\n",
            "Macro Avg      & 0.5793 & 0.9449 & 0.6329 & 28481 \\\\\n",
            "Weighted Avg   & 0.9984 & 0.9916 & 0.9945 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training LinearSVM-10...\n",
            "\n",
            "=== LinearSVM-10 ===\n",
            "Accuracy: 0.9778 | Precision: 0.0669 | Recall: 0.9184 | F1: 0.1247\n",
            "ROC-AUC: 0.9637 | PR-AUC: 0.7386\n",
            "Confusion Matrix:\n",
            " [[27804   628]\n",
            " [    4    45]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9999 & 0.9779 & 0.9888 & 28432 \\\\\n",
            "Fraud          & 0.0669 & 0.9184 & 0.1247 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9778 & 28481 \\\\\n",
            "Macro Avg      & 0.5334 & 0.9481 & 0.5567 & 28481 \\\\\n",
            "Weighted Avg   & 0.9983 & 0.9778 & 0.9873 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training LinearSVM-30...\n",
            "\n",
            "=== LinearSVM-30 ===\n",
            "Accuracy: 0.9778 | Precision: 0.0669 | Recall: 0.9184 | F1: 0.1247\n",
            "ROC-AUC: 0.9637 | PR-AUC: 0.7386\n",
            "Confusion Matrix:\n",
            " [[27804   628]\n",
            " [    4    45]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9999 & 0.9779 & 0.9888 & 28432 \\\\\n",
            "Fraud          & 0.0669 & 0.9184 & 0.1247 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9778 & 28481 \\\\\n",
            "Macro Avg      & 0.5334 & 0.9481 & 0.5567 & 28481 \\\\\n",
            "Weighted Avg   & 0.9983 & 0.9778 & 0.9873 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training LinearSVM-50...\n",
            "\n",
            "=== LinearSVM-50 ===\n",
            "Accuracy: 0.9778 | Precision: 0.0669 | Recall: 0.9184 | F1: 0.1247\n",
            "ROC-AUC: 0.9637 | PR-AUC: 0.7386\n",
            "Confusion Matrix:\n",
            " [[27804   628]\n",
            " [    4    45]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9999 & 0.9779 & 0.9888 & 28432 \\\\\n",
            "Fraud          & 0.0669 & 0.9184 & 0.1247 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9778 & 28481 \\\\\n",
            "Macro Avg      & 0.5334 & 0.9481 & 0.5567 & 28481 \\\\\n",
            "Weighted Avg   & 0.9983 & 0.9778 & 0.9873 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training MLP-10...\n",
            "\n",
            "=== MLP-10 ===\n",
            "Accuracy: 0.9992 | Precision: 0.7407 | Recall: 0.8163 | F1: 0.7767\n",
            "ROC-AUC: 0.9406 | PR-AUC: 0.8125\n",
            "Confusion Matrix:\n",
            " [[28418    14]\n",
            " [    9    40]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9997 & 0.9995 & 0.9996 & 28432 \\\\\n",
            "Fraud          & 0.7407 & 0.8163 & 0.7767 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9992 & 28481 \\\\\n",
            "Macro Avg      & 0.8702 & 0.9079 & 0.8881 & 28481 \\\\\n",
            "Weighted Avg   & 0.9992 & 0.9992 & 0.9992 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training MLP-30...\n",
            "\n",
            "=== MLP-30 ===\n",
            "Accuracy: 0.9992 | Precision: 0.7358 | Recall: 0.7959 | F1: 0.7647\n",
            "ROC-AUC: 0.9546 | PR-AUC: 0.8057\n",
            "Confusion Matrix:\n",
            " [[28418    14]\n",
            " [   10    39]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9996 & 0.9995 & 0.9996 & 28432 \\\\\n",
            "Fraud          & 0.7358 & 0.7959 & 0.7647 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9992 & 28481 \\\\\n",
            "Macro Avg      & 0.8677 & 0.8977 & 0.8821 & 28481 \\\\\n",
            "Weighted Avg   & 0.9992 & 0.9992 & 0.9992 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "Training MLP-50...\n",
            "\n",
            "=== MLP-50 ===\n",
            "Accuracy: 0.9992 | Precision: 0.7451 | Recall: 0.7755 | F1: 0.7600\n",
            "ROC-AUC: 0.9501 | PR-AUC: 0.7859\n",
            "Confusion Matrix:\n",
            " [[28419    13]\n",
            " [   11    38]]\n",
            "\n",
            "LaTeX Classification Report:\n",
            "\n",
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lcccc}\n",
            "\\hline\n",
            "\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
            "\\hline\n",
            "Non-Fraud      & 0.9996 & 0.9995 & 0.9996 & 28432 \\\\\n",
            "Fraud          & 0.7451 & 0.7755 & 0.7600 & 49 \\\\\n",
            "\\hline\n",
            "Accuracy       &        &        & 0.9992 & 28481 \\\\\n",
            "Macro Avg      & 0.8724 & 0.8875 & 0.8798 & 28481 \\\\\n",
            "Weighted Avg   & 0.9992 & 0.9992 & 0.9992 & 28481 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Classification Report}\n",
            "\\label{tab:classification_report}\n",
            "\\end{table}\n",
            "\n",
            "=== Summary (sorted by PR-AUC) ===\n",
            "                  model  accuracy  precision    recall        f1   roc_auc  \\\n",
            "4       RandomForest-10  0.999579   0.930233  0.816327  0.869565  0.960577   \n",
            "5       RandomForest-30  0.999544   0.909091  0.816327  0.860215  0.963556   \n",
            "6       RandomForest-50  0.999544   0.909091  0.816327  0.860215  0.962110   \n",
            "13               MLP-10  0.999192   0.740741  0.816327  0.776699  0.940573   \n",
            "14               MLP-30  0.999157   0.735849  0.795918  0.764706  0.954626   \n",
            "15               MLP-50  0.999157   0.745098  0.775510  0.760000  0.950056   \n",
            "11         LinearSVM-30  0.977810   0.066865  0.918367  0.124654  0.963737   \n",
            "10         LinearSVM-10  0.977810   0.066865  0.918367  0.124654  0.963737   \n",
            "12         LinearSVM-50  0.977810   0.066865  0.918367  0.124654  0.963737   \n",
            "0    LogisticRegression  0.973526   0.056604  0.918367  0.106635  0.957580   \n",
            "8   GradientBoosting-30  0.991644   0.158845  0.897959  0.269939  0.972096   \n",
            "7   GradientBoosting-10  0.991644   0.158845  0.897959  0.269939  0.972096   \n",
            "9   GradientBoosting-50  0.991644   0.158845  0.897959  0.269939  0.972096   \n",
            "3       DecisionTree-50  0.997472   0.383838  0.775510  0.513514  0.886682   \n",
            "1       DecisionTree-10  0.997367   0.370000  0.755102  0.496644  0.876443   \n",
            "2       DecisionTree-30  0.997261   0.359223  0.755102  0.486842  0.876390   \n",
            "\n",
            "      pr_auc  \n",
            "4   0.875000  \n",
            "5   0.874707  \n",
            "6   0.874184  \n",
            "13  0.812461  \n",
            "14  0.805664  \n",
            "15  0.785930  \n",
            "11  0.738636  \n",
            "10  0.738636  \n",
            "12  0.738636  \n",
            "0   0.716127  \n",
            "8   0.676006  \n",
            "7   0.676006  \n",
            "9   0.676006  \n",
            "3   0.298057  \n",
            "1   0.279809  \n",
            "2   0.271672  \n",
            "\n",
            "=== Average Scores Across Random Seeds ===\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate\n",
        "results = []\n",
        "average_scores = {\n",
        "    'precision': {\n",
        "        'LogisticRegression': [],\n",
        "        'DecisionTree': [],\n",
        "        'RandomForest': [],\n",
        "        'GradientBoosting': [],\n",
        "        'LinearSVM': [],\n",
        "        'MLP': [],\n",
        "    },\n",
        "    'recall': {\n",
        "        'LogisticRegression': [],\n",
        "        'DecisionTree': [],\n",
        "        'RandomForest': [],\n",
        "        'GradientBoosting': [],\n",
        "        'LinearSVM': [],\n",
        "        'MLP': [],\n",
        "    },\n",
        "    'f1': {\n",
        "        'LogisticRegression': [],\n",
        "        'DecisionTree': [],\n",
        "        'RandomForest': [],\n",
        "        'GradientBoosting': [],\n",
        "        'LinearSVM': [],\n",
        "        'MLP': [],\n",
        "    },\n",
        "    'pr_auc': {\n",
        "        'LogisticRegression': [],\n",
        "        'DecisionTree': [],\n",
        "        'RandomForest': [],\n",
        "        'GradientBoosting': [],\n",
        "        'LinearSVM': [],\n",
        "        'MLP': [],\n",
        "    },\n",
        "}\n",
        "\n",
        "for name, model in models:\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    metrics = evaluate_classifier(model, X_test, y_test, name)\n",
        "    base_name = name.split('-')[0]\n",
        "    average_scores['precision'][base_name].append(metrics['precision'])\n",
        "    average_scores['recall'][base_name].append(metrics['recall'])\n",
        "    average_scores['f1'][base_name].append(metrics['f1'])\n",
        "    average_scores['pr_auc'][base_name].append(metrics['pr_auc'])\n",
        "    results.append(metrics)\n",
        "\n",
        "# Create summary DataFrame\n",
        "results_df = pd.DataFrame([{k: v for k, v in r.items() if k not in ['confusion_matrix']} for r in results])\n",
        "results_df = results_df.sort_values(by='pr_auc', ascending=False)\n",
        "print('\\n=== Summary (sorted by PR-AUC) ===')\n",
        "print(results_df[['model','accuracy','precision','recall','f1','roc_auc','pr_auc']])\n",
        "\n",
        "# Compute and display average scores across different random seeds\n",
        "print('\\n=== Average Scores Across Random Seeds ===')\n",
        "average_results = []\n",
        "for model_name in average_scores['precision'].keys():\n",
        "    avg_precision = np.mean(average_scores['precision'][model_name])\n",
        "    avg_recall = np.mean(average_scores['recall'][model_name])\n",
        "    avg_f1 = np.mean(average_scores['f1'][model_name])\n",
        "    avg_pr_auc = np.mean(average_scores['pr_auc'][model_name])\n",
        "    average_results.append({\n",
        "        'model': model_name,\n",
        "        'avg_precision': avg_precision,\n",
        "        'avg_recall': avg_recall,\n",
        "        'avg_f1': avg_f1,\n",
        "        'avg_pr_auc': avg_pr_auc\n",
        "    })\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}